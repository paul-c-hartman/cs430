{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761fb442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXERCISE 1: Agent-Environment Interaction\n",
      "======================================================================\n",
      "\n",
      "Initial state: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "Current percept: (<Location.A: 'A'>, <Status.DIRTY: 'Dirty'>)\n",
      "\n",
      "Executing actions manually:\n",
      "After SUCK: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "After RIGHT: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "After SUCK: [Clean] Agent@B [Clean] | Perf: 19\n",
      "\n",
      "Final Performance: 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 1: Agents and Environments\n",
    "\"\"\"\n",
    "import random\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "class Location(Enum):\n",
    "    A = \"A\"\n",
    "    B = \"B\"\n",
    "\n",
    "class Status(Enum):\n",
    "    CLEAN = \"Clean\"\n",
    "    DIRTY = \"Dirty\"\n",
    "\n",
    "class Action(Enum):\n",
    "    LEFT = \"Left\"\n",
    "    RIGHT = \"Right\"\n",
    "    SUCK = \"Suck\"\n",
    "    NOOP = \"NoOp\"\n",
    "\n",
    "class VacuumEnvironment:\n",
    "    \"\"\"Simple two-location vacuum environment\"\"\"\n",
    "    def __init__(self):\n",
    "        self.locations = {Location.A: Status.DIRTY, Location.B: Status.DIRTY}\n",
    "        self.agent_location = Location.A\n",
    "        self.performance = 0\n",
    "        self.time_steps = 0\n",
    "    \n",
    "    def percept(self) -> Tuple[Location, Status]:\n",
    "        \"\"\"Return current percept: [Location, Status]\"\"\"\n",
    "        return (self.agent_location, self.locations[self.agent_location])\n",
    "    \n",
    "    def execute(self, action: Action):\n",
    "        \"\"\"Execute action and update environment\"\"\"\n",
    "        self.time_steps += 1\n",
    "        \n",
    "        if action == Action.SUCK:\n",
    "            if self.locations[self.agent_location] == Status.DIRTY:\n",
    "                self.locations[self.agent_location] = Status.CLEAN\n",
    "                self.performance += 10  # Reward for cleaning\n",
    "        elif action == Action.LEFT:\n",
    "            self.agent_location = Location.A\n",
    "            self.performance -= 1  # Cost of movement\n",
    "        elif action == Action.RIGHT:\n",
    "            self.agent_location = Location.B\n",
    "            self.performance -= 1  # Cost of movement\n",
    "    \n",
    "    def is_clean(self) -> bool:\n",
    "        return all(status == Status.CLEAN for status in self.locations.values())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[{self.locations[Location.A].value}] Agent@{self.agent_location.value} [{self.locations[Location.B].value}] | Perf: {self.performance}\"\n",
    "\n",
    "# Demonstration\n",
    "print(\"=\"*70)\n",
    "print(\"EXERCISE 1: Agent-Environment Interaction\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "print(f\"\\nInitial state: {env}\")\n",
    "print(f\"Current percept: {env.percept()}\")\n",
    "print(\"\\nExecuting actions manually:\")\n",
    "\n",
    "# Manual action sequence\n",
    "env.execute(Action.SUCK)\n",
    "print(f\"After SUCK: {env}\")\n",
    "\n",
    "env.execute(Action.RIGHT)\n",
    "print(f\"After RIGHT: {env}\")\n",
    "\n",
    "env.execute(Action.SUCK)\n",
    "print(f\"After SUCK: {env}\")\n",
    "\n",
    "print(f\"\\nFinal Performance: {env.performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183536ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 2: Simple Reflex Agent Behavior\n",
      "======================================================================\n",
      "\n",
      "Agent Rules:\n",
      "  - IF dirty THEN suck\n",
      "  - IF at A and clean THEN move right\n",
      "  - IF at B and clean THEN move left\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Percept: (<Location.A: 'A'>, <Status.DIRTY: 'Dirty'>) → Action: Suck\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Percept: (<Location.A: 'A'>, <Status.CLEAN: 'Clean'>) → Action: Right\n",
      "Step 2: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Percept: (<Location.B: 'B'>, <Status.DIRTY: 'Dirty'>) → Action: Suck\n",
      "\n",
      "Step 3: [Clean] Agent@B [Clean] | Perf: 19\n",
      "✓ All locations clean!\n",
      "\n",
      "Final Performance Score: 19\n",
      "Steps taken: 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 2: Simple Reflex Agent (Rational Behavior)\n",
    "\"\"\"\n",
    "\n",
    "def simple_reflex_vacuum_agent(percept: Tuple[Location, Status]) -> Action:\n",
    "    \"\"\"\n",
    "    Agent function: maps current percept to action\n",
    "    Rules:\n",
    "      - If current location is dirty → SUCK\n",
    "      - If at location A and clean → move RIGHT\n",
    "      - If at location B and clean → move LEFT\n",
    "    \"\"\"\n",
    "    location, status = percept\n",
    "    \n",
    "    if status == Status.DIRTY:\n",
    "        return Action.SUCK\n",
    "    elif location == Location.A:\n",
    "        return Action.RIGHT\n",
    "    else:\n",
    "        return Action.LEFT\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 2: Simple Reflex Agent Behavior\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAgent Rules:\")\n",
    "print(\"  - IF dirty THEN suck\")\n",
    "print(\"  - IF at A and clean THEN move right\")\n",
    "print(\"  - IF at B and clean THEN move left\")\n",
    "print()\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "for step in range(8):\n",
    "    percept = env.percept()\n",
    "    action = simple_reflex_vacuum_agent(percept)\n",
    "    print(f\"Step {step}: {env}\")\n",
    "    print(f\"  Percept: {percept} → Action: {action.value}\")\n",
    "    env.execute(action)\n",
    "    if env.is_clean():\n",
    "        print(f\"\\nStep {step+1}: {env}\")\n",
    "        print(\"✓ All locations clean!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal Performance Score: {env.performance}\")\n",
    "print(f\"Steps taken: {env.time_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a8f6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 3: Stochastic Environment\n",
      "======================================================================\n",
      "\n",
      "Environment: SUCK action has 70% success rate\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Action: Suck\n",
      "    ⚠ SUCK action failed!\n",
      "Step 1: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Action: Suck\n",
      "Step 2: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Action: Right\n",
      "Step 3: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "    ⚠ SUCK action failed!\n",
      "Step 4: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "\n",
      "✓ All locations clean!\n",
      "\n",
      "Final Performance: 19\n",
      "Total steps: 5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 3: Environment Properties - Stochasticity\n",
    "\"\"\"\n",
    "\n",
    "class StochasticVacuumEnvironment(VacuumEnvironment):\n",
    "    \"\"\"Vacuum environment where SUCK action may fail\"\"\"\n",
    "    def execute(self, action: Action):\n",
    "        self.time_steps += 1\n",
    "        \n",
    "        if action == Action.SUCK:\n",
    "            if self.locations[self.agent_location] == Status.DIRTY:\n",
    "                # Only 70% success rate\n",
    "                if random.random() > 0.3:\n",
    "                    self.locations[self.agent_location] = Status.CLEAN\n",
    "                    self.performance += 10\n",
    "                else:\n",
    "                    print(\"    ⚠ SUCK action failed!\")\n",
    "        elif action == Action.LEFT:\n",
    "            self.agent_location = Location.A\n",
    "            self.performance -= 1\n",
    "        elif action == Action.RIGHT:\n",
    "            self.agent_location = Location.B\n",
    "            self.performance -= 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 3: Stochastic Environment\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEnvironment: SUCK action has 70% success rate\")\n",
    "print()\n",
    "\n",
    "random.seed(49)  # For reproducible results\n",
    "env_stochastic = StochasticVacuumEnvironment()\n",
    "\n",
    "for step in range(15):\n",
    "    percept = env_stochastic.percept()\n",
    "    action = simple_reflex_vacuum_agent(percept)\n",
    "    print(f\"Step {step}: {env_stochastic}\")\n",
    "    print(f\"  Action: {action.value}\")\n",
    "    env_stochastic.execute(action)\n",
    "    if env_stochastic.is_clean():\n",
    "        print(f\"\\n✓ All locations clean!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal Performance: {env_stochastic.performance}\")\n",
    "print(f\"Total steps: {env_stochastic.time_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84064e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 4: Model-Based Reflex Agent\n",
      "======================================================================\n",
      "\n",
      "Agent maintains internal model of both locations\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Agent's Model: A=Dirty, B=Dirty\n",
      "  Action: Suck\n",
      "\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Agent's Model: A=Clean, B=Dirty\n",
      "  Action: Right\n",
      "\n",
      "Step 2: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Agent's Model: A=Clean, B=Dirty\n",
      "  Action: Suck\n",
      "\n",
      "Step 3: [Clean] Agent@B [Clean] | Perf: 19\n",
      "  Agent's Model: A=Clean, B=Clean\n",
      "  Action: NoOp\n",
      "\n",
      "✓ Agent believes task is complete\n",
      "Final Performance: 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 4: Model-Based Reflex Agent\n",
    "\"\"\"\n",
    "\n",
    "class ModelBasedVacuumAgent:\n",
    "    \"\"\"Agent that maintains internal state about the world\"\"\"\n",
    "    def __init__(self):\n",
    "        # Internal model of the world state\n",
    "        self.model = {Location.A: Status.DIRTY, Location.B: Status.DIRTY}\n",
    "        self.location = Location.A\n",
    "    \n",
    "    def agent_program(self, percept: Tuple[Location, Status]) -> Action:\n",
    "        location, status = percept\n",
    "        \n",
    "        # Update internal model based on percept\n",
    "        self.location = location\n",
    "        self.model[location] = status\n",
    "        \n",
    "        # Decide action based on model\n",
    "        if status == Status.DIRTY:\n",
    "            return Action.SUCK\n",
    "        elif self.model[Location.A] == Status.DIRTY:\n",
    "            return Action.LEFT\n",
    "        elif self.model[Location.B] == Status.DIRTY:\n",
    "            return Action.RIGHT\n",
    "        else:\n",
    "            return Action.NOOP  # Believes all locations clean\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 4: Model-Based Reflex Agent\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAgent maintains internal model of both locations\")\n",
    "print()\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "agent = ModelBasedVacuumAgent()\n",
    "\n",
    "for step in range(10):\n",
    "    percept = env.percept()\n",
    "    action = agent.agent_program(percept)\n",
    "    print(f\"Step {step}: {env}\")\n",
    "    print(f\"  Agent's Model: A={agent.model[Location.A].value}, B={agent.model[Location.B].value}\")\n",
    "    print(f\"  Action: {action.value}\")\n",
    "    env.execute(action)\n",
    "    print()\n",
    "    if action == Action.NOOP:\n",
    "        print(\"✓ Agent believes task is complete\")\n",
    "        break\n",
    "\n",
    "print(f\"Final Performance: {env.performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41dd521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 5: Goal-Based Agent\n",
      "======================================================================\n",
      "\n",
      "Goal: Visit and clean all locations\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Visited: ['A']\n",
      "  Cleaned: []\n",
      "  Action: Suck\n",
      "\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Visited: ['A']\n",
      "  Cleaned: ['A']\n",
      "  Action: Left\n",
      "\n",
      "Step 2: [Clean] Agent@A [Dirty] | Perf: 9\n",
      "  Visited: ['A']\n",
      "  Cleaned: ['A']\n",
      "  Action: Left\n",
      "\n",
      "Step 3: [Clean] Agent@A [Dirty] | Perf: 8\n",
      "  Visited: ['A']\n",
      "  Cleaned: ['A']\n",
      "  Action: Right\n",
      "\n",
      "Step 4: [Clean] Agent@B [Dirty] | Perf: 7\n",
      "  Visited: ['A', 'B']\n",
      "  Cleaned: ['A']\n",
      "  Action: Suck\n",
      "\n",
      "Step 5: [Clean] Agent@B [Clean] | Perf: 17\n",
      "  Visited: ['A', 'B']\n",
      "  Cleaned: ['A', 'B']\n",
      "  Action: NoOp\n",
      "\n",
      "✓ Goal achieved!\n",
      "Final Performance: 17\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 5: Goal-Based Agent\n",
    "\"\"\"\n",
    "\n",
    "class GoalBasedVacuumAgent:\n",
    "    \"\"\"Agent that plans actions to achieve explicit goals\"\"\"\n",
    "    def __init__(self):\n",
    "        self.goal = \"all locations visited and clean\"\n",
    "        self.visited = set()\n",
    "        self.cleaned = set()\n",
    "    \n",
    "    def agent_program(self, percept: Tuple[Location, Status]) -> Action:\n",
    "        location, status = percept\n",
    "        self.visited.add(location)\n",
    "        \n",
    "        # Subgoal: Clean current location if dirty\n",
    "        if status == Status.DIRTY:\n",
    "            return Action.SUCK\n",
    "        else:\n",
    "            self.cleaned.add(location)\n",
    "        \n",
    "        # Plan: Visit unvisited locations\n",
    "        if Location.A not in self.visited:\n",
    "            return random.choice([Action.LEFT, Action.RIGHT])\n",
    "        elif Location.B not in self.visited:\n",
    "            return random.choice([Action.LEFT, Action.RIGHT])\n",
    "        else:\n",
    "            # Goal achieved: all locations visited and clean\n",
    "            return Action.NOOP\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 5: Goal-Based Agent\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nGoal: Visit and clean all locations\")\n",
    "print()\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "agent = GoalBasedVacuumAgent()\n",
    "\n",
    "for step in range(10):\n",
    "    percept = env.percept()\n",
    "    action = agent.agent_program(percept)\n",
    "    print(f\"Step {step}: {env}\")\n",
    "    print(f\"  Visited: {sorted([loc.value for loc in agent.visited])}\")\n",
    "    print(f\"  Cleaned: {sorted([loc.value for loc in agent.cleaned])}\")\n",
    "    print(f\"  Action: {action.value}\")\n",
    "    env.execute(action)\n",
    "    print()\n",
    "    if action == Action.NOOP:\n",
    "        print(\"✓ Goal achieved!\")\n",
    "        break\n",
    "\n",
    "print(f\"Final Performance: {env.performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981131fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 6: Utility-Based Agent\n",
      "======================================================================\n",
      "\n",
      "Utility Function: +10 per clean location, -1 per move\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Current state utility: 0\n",
      "  Chosen action: Suck\n",
      "\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Current state utility: 0\n",
      "  Chosen action: Right\n",
      "\n",
      "Step 2: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Current state utility: 10\n",
      "  Chosen action: Suck\n",
      "\n",
      "✓ All locations clean!\n",
      "Final Performance: 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 6: Utility-Based Agent\n",
    "\"\"\"\n",
    "\n",
    "class UtilityBasedVacuumAgent:\n",
    "    \"\"\"Agent that maximizes expected utility\"\"\"\n",
    "    def __init__(self):\n",
    "        self.state = {Location.A: Status.DIRTY, Location.B: Status.DIRTY}\n",
    "        self.location = Location.A\n",
    "    \n",
    "    def utility(self, state: dict) -> float:\n",
    "        \"\"\"Calculate utility of a state\"\"\"\n",
    "        clean_count = sum(1 for s in state.values() if s == Status.CLEAN)\n",
    "        return clean_count * 10  # 10 points per clean location\n",
    "    \n",
    "    def expected_utility(self, action: Action) -> float:\n",
    "        \"\"\"Predict utility after taking action (minus costs)\"\"\"\n",
    "        next_state = self.state.copy()\n",
    "        next_location = self.location\n",
    "        \n",
    "        if action == Action.SUCK:\n",
    "            if self.state[self.location] == Status.DIRTY:\n",
    "                next_state[self.location] = Status.CLEAN\n",
    "            return self.utility(next_state) - 0  # No cost\n",
    "        elif action == Action.LEFT:\n",
    "            next_location = Location.A\n",
    "            # Expected utility: might find dirt there\n",
    "            if next_state[Location.A] == Status.DIRTY:\n",
    "                # If we know it's dirty, we can clean it (net +9)\n",
    "                return self.utility(next_state) + 10 - 1\n",
    "            return self.utility(next_state) - 1  # Just movement cost\n",
    "        elif action == Action.RIGHT:\n",
    "            next_location = Location.B\n",
    "            # Expected utility: might find dirt there\n",
    "            if next_state[Location.B] == Status.DIRTY:\n",
    "                # If we know it's dirty, we can clean it (net +9)\n",
    "                return self.utility(next_state) + 10 - 1\n",
    "            return self.utility(next_state) - 1  # Just movement cost\n",
    "        return self.utility(next_state)\n",
    "    \n",
    "    def agent_program(self, percept: Tuple[Location, Status]) -> Action:\n",
    "        location, status = percept\n",
    "        self.location = location\n",
    "        self.state[location] = status\n",
    "        \n",
    "        # Evaluate all possible actions\n",
    "        actions = [Action.SUCK, Action.LEFT, Action.RIGHT]\n",
    "        action_utilities = []\n",
    "        \n",
    "        for a in actions:\n",
    "            eu = self.expected_utility(a)\n",
    "            action_utilities.append((a, eu))\n",
    "        \n",
    "        # Choose action with maximum expected utility\n",
    "        best_action = max(action_utilities, key=lambda x: x[1])\n",
    "        \n",
    "        return best_action[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 6: Utility-Based Agent\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUtility Function: +10 per clean location, -1 per move\")\n",
    "print()\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "agent = UtilityBasedVacuumAgent()\n",
    "\n",
    "for step in range(10):\n",
    "    percept = env.percept()\n",
    "    \n",
    "    # Show utility calculation\n",
    "    print(f\"Step {step}: {env}\")\n",
    "    print(f\"  Current state utility: {agent.utility(agent.state)}\")\n",
    "    \n",
    "    # Get action\n",
    "    action = agent.agent_program(percept)\n",
    "    print(f\"  Chosen action: {action.value}\")\n",
    "    \n",
    "    env.execute(action)\n",
    "    print()\n",
    "    if env.is_clean():\n",
    "        print(\"✓ All locations clean!\")\n",
    "        break\n",
    "\n",
    "print(f\"Final Performance: {env.performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685ddb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 7: Agent Performance Comparison\n",
      "======================================================================\n",
      "\n",
      "Running all four agent types in identical environments...\n",
      "\n",
      "Results:\n",
      "----------------------------------------------------------------------\n",
      "Agent Type           Performance     Steps     \n",
      "----------------------------------------------------------------------\n",
      "Simple Reflex        19              3         \n",
      "Model-Based          19              4         \n",
      "Goal-Based           19              4         \n",
      "Utility-Based        19              3         \n",
      "----------------------------------------------------------------------\n",
      "\n",
      " Best Performance: Simple Reflex (Score: 19)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 7: Comparing All Agent Types\n",
    "\"\"\"\n",
    "\n",
    "def run_agent_comparison():\n",
    "    \"\"\"Run all four agent types and compare performance\"\"\"\n",
    "    \n",
    "    def run_simple_reflex(max_steps=10):\n",
    "        env = VacuumEnvironment()\n",
    "        for _ in range(max_steps):\n",
    "            action = simple_reflex_vacuum_agent(env.percept())\n",
    "            env.execute(action)\n",
    "            if env.is_clean():\n",
    "                break\n",
    "        return env.performance, env.time_steps\n",
    "    \n",
    "    def run_model_based(max_steps=10):\n",
    "        env = VacuumEnvironment()\n",
    "        agent = ModelBasedVacuumAgent()\n",
    "        for _ in range(max_steps):\n",
    "            action = agent.agent_program(env.percept())\n",
    "            env.execute(action)\n",
    "            if action == Action.NOOP:\n",
    "                break\n",
    "        return env.performance, env.time_steps\n",
    "    \n",
    "    def run_goal_based(max_steps=10):\n",
    "        env = VacuumEnvironment()\n",
    "        agent = GoalBasedVacuumAgent()\n",
    "        for _ in range(max_steps):\n",
    "            action = agent.agent_program(env.percept())\n",
    "            env.execute(action)\n",
    "            if action == Action.NOOP:\n",
    "                break\n",
    "        return env.performance, env.time_steps\n",
    "    \n",
    "    def run_utility_based(max_steps=10):\n",
    "        env = VacuumEnvironment()\n",
    "        agent = UtilityBasedVacuumAgent()\n",
    "        for _ in range(max_steps):\n",
    "            action = agent.agent_program(env.percept())\n",
    "            env.execute(action)\n",
    "            if env.is_clean():\n",
    "                break\n",
    "        return env.performance, env.time_steps\n",
    "    \n",
    "    return {\n",
    "        \"Simple Reflex\": run_simple_reflex(),\n",
    "        \"Model-Based\": run_model_based(),\n",
    "        \"Goal-Based\": run_goal_based(),\n",
    "        \"Utility-Based\": run_utility_based()\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 7: Agent Performance Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRunning all four agent types in identical environments...\\n\")\n",
    "\n",
    "results = run_agent_comparison()\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Agent Type':<20} {'Performance':<15} {'Steps':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for agent_type, (perf, steps) in results.items():\n",
    "    print(f\"{agent_type:<20} {perf:<15} {steps:<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Find best performer\n",
    "best_agent = max(results.items(), key=lambda x: x[1][0])\n",
    "print(f\"\\n Best Performance: {best_agent[0]} (Score: {best_agent[1][0]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
